{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a763122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def judge_node_same(obs_nodes_info_a, obs_nodes_info_b, threshold=3):\n",
    "    \"\"\"\n",
    "    判断两个状态之间的节点差异是否超过阈值\n",
    "    obs_nodes_info_a 和 b 都是一个字典，字典的key是节点id，value 是一个字典，例如：\n",
    "    '11765': {'backend_id': 19269,\n",
    "    'union_bound': [0.0, 0.0, 10.0, 10.0],\n",
    "    'text': \"[11765] RootWebArea 'Postmill' focused: True\"}\n",
    "\n",
    "    对于 obs_nodes_info_a 的一个元素，如果 obs_nodes_info_b 中存在一个元素，其 union_bound 一致，并且 text 去掉 [xxx] 后一致，则认为两个元素是相同的\n",
    "    如果不同的元素小于 threshold，则认为两个状态是相同的\n",
    "    这里所谓的 key 和 backend_id 都不重要，不作为参考依据\n",
    "\n",
    "    返回值：\n",
    "    - 如果两个状态差异小于等于 threshold，相同，返回 True\n",
    "    - 如果两个状态差异超过阈值，返回 False\n",
    "    \"\"\"\n",
    "\n",
    "    diff_count = 0\n",
    "\n",
    "    b_nodes_set = set()\n",
    "    for node_id, node_info in obs_nodes_info_b.items():\n",
    "        union_bound = node_info['union_bound']\n",
    "        cleaned_text = re.sub(r'\\[.*?\\]', '', node_info['text'])\n",
    "        b_nodes_set.add(f\"{union_bound}_{cleaned_text}\")\n",
    "\n",
    "    for node_id, node_info in obs_nodes_info_a.items():\n",
    "        union_bound = node_info['union_bound']\n",
    "        cleaned_text = re.sub(r'\\[.*?\\]', '', node_info['text'])\n",
    "        if f\"{union_bound}_{cleaned_text}\" not in b_nodes_set:\n",
    "            diff_count += 1\n",
    "    # print(diff_count)\n",
    "    return diff_count <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3356de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a11y_to_components(a11y):\n",
    "    \"\"\"\n",
    "    将 a11y 转换为组件列表\n",
    "    \"\"\"\n",
    "    # 对于每一行\n",
    "    # 如果包含 [xxx]，则去掉 [xxx]，将后面的内容视作一个组件\n",
    "\n",
    "    components = []\n",
    "    for line in a11y.split(\"\\n\"):\n",
    "        # 去掉前后空格\n",
    "        line = line.strip()\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        match = re.match(r'\\[(\\d+)\\]', line)\n",
    "        if match:\n",
    "            # component_id = match.group(1)\n",
    "            component_content = line[match.end():].strip()\n",
    "            components.append(component_content)\n",
    "        else:\n",
    "            components.append(line)\n",
    "    return components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2e6a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_node_same_from_a11y(a11y_a, a11y_b, threshold=3):\n",
    "    \"\"\"\n",
    "    判断两个状态之间的节点差异是否超过阈值\n",
    "    a11y_a 和 b 都是一个字符串，字符串的格式为例如：\n",
    "    [5207] heading 'relationship_advice — relationship_advice'\n",
    "        [5209] link 'relationship_advice — relationship_advice'\n",
    "    [5215] button 'Subscribe No subscribers'\n",
    "        [5571] generic 'No subscribers'\n",
    "    [5216] StaticText '5,721 submissions'\n",
    "\n",
    "    首先去掉前面的 [xxx]，将后面的内容视作一个组件\n",
    "\n",
    "    对于 a11y_a 的一个组件，如果 a11y_b 中存在一个组件，其组件内容一致，则认为两个组件是相同的\n",
    "    如果不同的组件小于 threshold，则认为两个状态是相同的\n",
    "\n",
    "    返回值：\n",
    "    - 如果两个状态差异小于等于 threshold，相同，返回 True\n",
    "    - 如果两个状态差异超过阈值，返回 False\n",
    "    \"\"\"\n",
    "\n",
    "    diff_count = 0\n",
    "\n",
    "    a_components = a11y_to_components(a11y_a)\n",
    "    b_components = a11y_to_components(a11y_b)\n",
    "\n",
    "    for a_component in a_components:\n",
    "        if a_component not in b_components:\n",
    "            diff_count += 1\n",
    "    # print(diff_count)\n",
    "    return diff_count <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ceecb588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# judge_node_same_from_a11y(trajs[0][\"a11y_before\"], trajs[2][\"a11y_after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fefcd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "def bm25_retrieval(query, corpus, top_n=3):\n",
    "    tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    tokenized_query = query.split(\" \")\n",
    "    top_n_docs = bm25.get_top_n(tokenized_query, corpus, n=top_n)\n",
    "    top_n_docs_index = [corpus.index(doc) for doc in top_n_docs]\n",
    "    return top_n_docs_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8237934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# judge_node_difference(data[0][\"state_before\"]['text']['obs_nodes_info'], data[2][\"state_after\"]['text']['obs_nodes_info'])\n",
    "# bm25_retrieval('a', ['bcc', 'a v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0492647a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_path = \"/home/zjusst/qms/webarena/result_stage_1_explore_v2/add_local_intention_trajs\"\n",
    "file_names = os.listdir(dir_path)\n",
    "file_names = [file_name for file_name in file_names if file_name.endswith(\".json\")]\n",
    "# file_names.sort() 自定义排序，按照 _ 分割，取后面的数字排序\n",
    "file_names.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "len(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a3fc9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/zjusst/qms/webarena/result_stage_1_explore_v2/add_local_intention_trajs/812_1.json\", \"r\") as f:\n",
    "#     trajs = json.load(f)\n",
    "\n",
    "# trajs[5]\n",
    "# trajs[1][\"state_after\"]\n",
    "# judge_node_same(trajs[i][\"state_before\"]['text']['obs_nodes_info'], trajs[i][\"state_after\"]['text']['obs_nodes_info'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdb9758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:11<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "unique_page_ids = []  # (file_name, traj_idx, 0|1代表前还是后, real_url) \n",
    "unique_page_a11ys = []\n",
    "unique_page_nodes = []\n",
    "records = []  # (page_id, action, intention, page_id)\n",
    "\n",
    "for file_name in tqdm(file_names):\n",
    "    with open(os.path.join(dir_path, file_name), \"r\") as f:\n",
    "        trajs = json.load(f)\n",
    "\n",
    "    for traj_idx, traj in enumerate(trajs):\n",
    "        if len(unique_page_ids) == 0:\n",
    "            unique_page_ids.append((file_name, traj_idx, 0, traj['url_real_before']))\n",
    "            unique_page_a11ys.append(traj[\"a11y_before\"])\n",
    "            unique_page_nodes.append(traj[\"state_before\"]['text']['obs_nodes_info'])\n",
    "\n",
    "        prev_page_id = -1\n",
    "        # 从 unique_page_a11ys 检索出最接近的三个\n",
    "        top_n_docs_index = bm25_retrieval(traj[\"a11y_before\"], unique_page_a11ys, 3)\n",
    "        for doc_idx in top_n_docs_index:\n",
    "            if judge_node_same(traj[\"state_before\"]['text']['obs_nodes_info'], unique_page_nodes[doc_idx], 0):\n",
    "                prev_page_id = unique_page_ids[doc_idx]\n",
    "                break\n",
    "            # if judge_node_same_from_a11y(traj[\"a11y_before\"], unique_page_a11ys[doc_idx], 3):\n",
    "            #     prev_page_id = unique_page_ids[doc_idx]\n",
    "            #     break\n",
    "        if prev_page_id == -1:\n",
    "            unique_page_ids.append((file_name, traj_idx, 0, traj['url_real_before']))\n",
    "            unique_page_a11ys.append(traj[\"a11y_before\"])\n",
    "            unique_page_nodes.append(traj[\"state_before\"]['text']['obs_nodes_info'])\n",
    "            prev_page_id = unique_page_ids[-1]\n",
    "\n",
    "        action_str = traj[\"action_str\"]\n",
    "        intention = traj[\"intention\"]\n",
    "\n",
    "        after_page_id = -1\n",
    "        top_n_docs_index = bm25_retrieval(traj[\"a11y_after\"], unique_page_a11ys, 3)\n",
    "        for doc_idx in top_n_docs_index:\n",
    "            if judge_node_same(traj[\"state_after\"]['text']['obs_nodes_info'], unique_page_nodes[doc_idx], 0):\n",
    "                after_page_id = unique_page_ids[doc_idx]\n",
    "                break\n",
    "            # if judge_node_same_from_a11y(traj[\"a11y_after\"], unique_page_a11ys[doc_idx], 3):\n",
    "            #     after_page_id = unique_page_ids[doc_idx]\n",
    "            #     break\n",
    "        if after_page_id == -1:\n",
    "            unique_page_ids.append((file_name, traj_idx, 1, traj['url_real_after']))\n",
    "            unique_page_a11ys.append(traj[\"a11y_after\"])\n",
    "            unique_page_nodes.append(traj[\"state_after\"]['text']['obs_nodes_info'])\n",
    "            after_page_id = unique_page_ids[-1]\n",
    "            \n",
    "        records.append((prev_page_id, action_str, intention, after_page_id))\n",
    "\n",
    "print(len(records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e26daca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_page_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25731745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('812_1.json', 0, 0, 'http://reddit.com/'),\n",
       " \"click [65] where [65] is link 'Forums'\",\n",
       " 'The user intends to navigate to the list of available forums to explore different communities or topics.',\n",
       " ('812_1.json', 0, 1, 'http://reddit.com/forums'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "222d5481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 1028)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_parsed_triplets = []\n",
    "for triplet in records:\n",
    "    temp_triplet = (\n",
    "        f\"{triplet[0][0]}_{triplet[0][1]}_{triplet[0][2]}_{triplet[0][3]}\",\n",
    "        triplet[1],\n",
    "        f\"{triplet[3][0]}_{triplet[3][1]}_{triplet[3][2]}_{triplet[3][3]}\"\n",
    "    )\n",
    "    action_parsed_triplets.append(temp_triplet)\n",
    "\n",
    "intention_parsed_triplets = []\n",
    "for triplet in records:\n",
    "    temp_triplet = (\n",
    "        f\"{triplet[0][0]}_{triplet[0][1]}_{triplet[0][2]}_{triplet[0][3]}\",\n",
    "        triplet[2],\n",
    "        f\"{triplet[3][0]}_{triplet[3][1]}_{triplet[3][2]}_{triplet[3][3]}\"\n",
    "    )\n",
    "    intention_parsed_triplets.append(temp_triplet)\n",
    "\n",
    "len(action_parsed_triplets), len(intention_parsed_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eaf5eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "interactive_graph_s1_v2_th0.html\n",
      "成功生成 'interactive_graph_s1_v2_th0.html' 文件！请在浏览器中打开查看。\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. 你的三元组数据 (用示例数据代替)\n",
    "# 在实际使用中，你会从文件中加载这些数据\n",
    "# 格式: (前页面标识, 动作描述, 后页面标识)\n",
    "# 页面标识可以是页面的URL、截图文件的哈希值或你定义的任何唯一ID\n",
    "# triplets = [\n",
    "#     ('HomePage', 'click(\"Login Button\")', 'LoginPage'),\n",
    "#     ('HomePage', 'click(\"Products Link\")', 'ProductsPage'),\n",
    "#     ('ProductsPage', 'click(\"Item 1\")', 'Item1_DetailsPage'),\n",
    "#     ('ProductsPage', 'click(\"Item 2\")', 'Item2_DetailsPage'),\n",
    "#     ('Item1_DetailsPage', 'click(\"Add to Cart\")', 'ShoppingCartPage'),\n",
    "#     ('Item2_DetailsPage', 'click(\"Add to Cart\")', 'ShoppingCartPage'),\n",
    "#     ('LoginPage', 'type(\"username & password\")', 'HomePage'), # 登录后回到主页\n",
    "#     ('ShoppingCartPage', 'go_back()', 'ProductsPage') # 从购物车返回\n",
    "# ]\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 2. 使用 NetworkX 创建一个有向图 (因为 A->B 和 B->A 是不同的)\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 3. 遍历三元组数据，填充图的节点和边\n",
    "for source, action, target in action_parsed_triplets:\n",
    "    # 添加节点 (如果节点已存在，NetworkX会自动忽略)\n",
    "    # 我们可以为节点添加属性，例如'title'，当鼠标悬停时会显示\n",
    "    G.add_node(source, title=f\"Page ID: {source}\")\n",
    "    G.add_node(target, title=f\"Page ID: {target}\")\n",
    "\n",
    "    # 添加边，并把动作描述作为边的标签\n",
    "    G.add_edge(source, target, label=action)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4. 使用 Pyvis 进行交互式可视化\n",
    "# 创建一个Pyvis网络图对象\n",
    "# notebook=True 如果你在Jupyter Notebook中使用\n",
    "# directed=True 会让边带上箭头，非常重要\n",
    "net = Network(height='2000px', width='100%', notebook=True, directed=True)\n",
    "\n",
    "# 从 NetworkX 对象加载图数据\n",
    "net.from_nx(G)\n",
    "\n",
    "# 为可视化添加一些物理引擎的选项，让布局更好看\n",
    "# net.toggle_physics(True)\n",
    "\n",
    "# 手动设定物理引擎参数\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"springLength\": 600\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# 添加交互UI的选项，例如筛选节点\n",
    "#net.show_buttons(filter_=['physics'])\n",
    "\n",
    "# 5. 生成HTML文件\n",
    "# 这个文件将保存在你的脚本所在的目录下\n",
    "# 你可以直接在浏览器中打开它\n",
    "net.show('interactive_graph_s1_v2_th0.html')\n",
    "\n",
    "print(\"成功生成 'interactive_graph_s1_v2_th0.html' 文件！请在浏览器中打开查看。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33be3993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "interactive_graph_s1_v2_th0_intention.html\n",
      "成功生成 'interactive_graph_s1_v2_th0_intention.html' 文件！请在浏览器中打开查看。\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. 你的三元组数据 (用示例数据代替)\n",
    "# 在实际使用中，你会从文件中加载这些数据\n",
    "# 格式: (前页面标识, 动作描述, 后页面标识)\n",
    "# 页面标识可以是页面的URL、截图文件的哈希值或你定义的任何唯一ID\n",
    "# triplets = [\n",
    "#     ('HomePage', 'click(\"Login Button\")', 'LoginPage'),\n",
    "#     ('HomePage', 'click(\"Products Link\")', 'ProductsPage'),\n",
    "#     ('ProductsPage', 'click(\"Item 1\")', 'Item1_DetailsPage'),\n",
    "#     ('ProductsPage', 'click(\"Item 2\")', 'Item2_DetailsPage'),\n",
    "#     ('Item1_DetailsPage', 'click(\"Add to Cart\")', 'ShoppingCartPage'),\n",
    "#     ('Item2_DetailsPage', 'click(\"Add to Cart\")', 'ShoppingCartPage'),\n",
    "#     ('LoginPage', 'type(\"username & password\")', 'HomePage'), # 登录后回到主页\n",
    "#     ('ShoppingCartPage', 'go_back()', 'ProductsPage') # 从购物车返回\n",
    "# ]\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 2. 使用 NetworkX 创建一个有向图 (因为 A->B 和 B->A 是不同的)\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 3. 遍历三元组数据，填充图的节点和边\n",
    "for source, action, target in intention_parsed_triplets:\n",
    "    # 添加节点 (如果节点已存在，NetworkX会自动忽略)\n",
    "    # 我们可以为节点添加属性，例如'title'，当鼠标悬停时会显示\n",
    "    G.add_node(source, title=f\"Page ID: {source}\")\n",
    "    G.add_node(target, title=f\"Page ID: {target}\")\n",
    "\n",
    "    # 添加边，并把动作描述作为边的标签\n",
    "    G.add_edge(source, target, label=action)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4. 使用 Pyvis 进行交互式可视化\n",
    "# 创建一个Pyvis网络图对象\n",
    "# notebook=True 如果你在Jupyter Notebook中使用\n",
    "# directed=True 会让边带上箭头，非常重要\n",
    "net = Network(height='2000px', width='100%', notebook=True, directed=True)\n",
    "\n",
    "# 从 NetworkX 对象加载图数据\n",
    "net.from_nx(G)\n",
    "\n",
    "# 为可视化添加一些物理引擎的选项，让布局更好看\n",
    "# net.toggle_physics(True)\n",
    "\n",
    "# 手动设定物理引擎参数\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"springLength\": 600\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# 添加交互UI的选项，例如筛选节点\n",
    "#net.show_buttons(filter_=['physics'])\n",
    "\n",
    "# 5. 生成HTML文件\n",
    "# 这个文件将保存在你的脚本所在的目录下\n",
    "# 你可以直接在浏览器中打开它\n",
    "net.show('interactive_graph_s1_v2_th0_intention.html')\n",
    "\n",
    "print(\"成功生成 'interactive_graph_s1_v2_th0_intention.html' 文件！请在浏览器中打开查看。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webarena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
