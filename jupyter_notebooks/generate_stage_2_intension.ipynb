{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649a82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956ea735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/home/zjusst/qms/webarena/result_stage_1_explore_v2/flitered_triplets.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    # 跳过第一行\n",
    "    next(reader)\n",
    "    triplets = [row for row in reader]\n",
    "len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec57a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"('812_1.json', 2, 1, 'http://reddit.com/create_forum')\", 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_degree_dict = {}\n",
    "for triplet in triplets:\n",
    "    if triplet[3] not in out_degree_dict:\n",
    "        out_degree_dict[triplet[3]] = 0\n",
    "    out_degree_dict[triplet[3]] += 1\n",
    "\n",
    "# 转为 list，由低到高排序\n",
    "out_degree_list = sorted(out_degree_dict.items(), key=lambda x: x[1])\n",
    "out_degree_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3a9d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flitered_out_degree_list = []\n",
    "for item in out_degree_list:\n",
    "    real_url = eval(item[0])[3]\n",
    "    if real_url.startswith(\"http://reddit.com/\"):\n",
    "        flitered_out_degree_list.append(item)\n",
    "\n",
    "len(flitered_out_degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e51fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"('812_1.json', 2, 1, 'http://reddit.com/create_forum')\", 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flitered_out_degree_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428ae1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['create_forum', 'submit', 'search', 'f', 'forums', 'user', 'comments', 'new', 'notifications', 'messages', 'tags'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_to_record_dict = {}\n",
    "for record in flitered_out_degree_list:\n",
    "    real_url = eval(record[0])[3]\n",
    "    # 去掉 http://reddit.com/ ，拿到后面部分\n",
    "    prefix = real_url.split(\"reddit.com/\")[1]\n",
    "    if prefix == \"\": \n",
    "        continue\n",
    "    # 如果 prefix 还存在 / 或者 ? ，取前面的部分\n",
    "    if \"/\" in prefix:\n",
    "        prefix = prefix.split(\"/\")[0]\n",
    "    if \"?\" in prefix:\n",
    "        prefix = prefix.split(\"?\")[0]\n",
    "    if prefix == \"wiki\":\n",
    "        continue\n",
    "    if prefix not in prefix_to_record_dict:\n",
    "        prefix_to_record_dict[prefix] = []\n",
    "    prefix_to_record_dict[prefix].append(record)\n",
    "prefix_to_record_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4addc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_url_and_a11y(prefix_to_record_dict):\n",
    "    # 种子为时间\n",
    "    random.seed(time.time())\n",
    "    # 随机选择一个 prefix\n",
    "    prefix = random.choice(list(prefix_to_record_dict.keys()))\n",
    "    record = prefix_to_record_dict[prefix][random.randint(0, len(prefix_to_record_dict[prefix]) - 1)]\n",
    "    file_name, traj_index, pos, real_url = eval(record[0])\n",
    "    with open(f\"/home/zjusst/qms/webarena/result_stage_1_explore_v2/add_local_intention_trajs/{file_name}\", \"r\") as f:\n",
    "        trajs = json.load(f)\n",
    "    traj = trajs[traj_index]\n",
    "    if pos == 0:\n",
    "        a11y = traj[\"a11y_before\"]\n",
    "    else:\n",
    "        a11y = traj[\"a11y_after\"]\n",
    "    return real_url, a11y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fb93586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://reddit.com/search?q=Boston+events'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_select_url_and_a11y(prefix_to_record_dict)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60cd4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_webarena_intension(k):\n",
    "    intensions = ['Like all submissions created by {{user}} in subreddit {{subreddit}}',\n",
    "        #'Ask for advice about {{issue}} in a subreddit for relations',\n",
    "        'Among the top {{number}} post in \"{{subreddit}}\" forum, {{description}}',\n",
    "        #'Post in the most appropriate subreddit and ask for recommendations for {{category}} products within a budget of {{price}}',\n",
    "        'Change my reddit bio to \"{{content}}\"',\n",
    "        #'Re-post the image of {{content}} in this page to {{subreddit}} subreddit and note \"from /f/pics\"',\n",
    "        #'Post a review of my recent reading \"{{book}}\" in the r/books with my comment \"{{content}}\".',\n",
    "        #'Post in {{subreddit}} forum about what could large language models help the correpong field.',\n",
    "        'Upvote the newest post in {{subreddit}} subreddit',\n",
    "        'DisLike all submissions created by {{user}} in subreddit {{subreddit}}',\n",
    "        #'Post a notice on a virtual meetup for {{interest}} enthusiasts on {{date}} in the {{subreddit}} subreddit',\n",
    "        'Open the thread of a trending post on the forum \"{{subreddit}}\" and subscribe.',\n",
    "        #'Post in {{subreddit}} subreddit about what could machine learning help the correpong field.',\n",
    "        #'Create a discussion post about \"{{topic}}\" in a relevant subreddit and ask users for their opinions with the simple prompt, \"your opinion\"',\n",
    "        #'Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the {{forum}} forum.',\n",
    "        #'Ask for product recommendations for {{category}} within a budget of {{price}} in {{subreddit}}',\n",
    "        #'Reply to {{position_description}} with my comment \"{{content_description}}\"',\n",
    "        'Create a new forum named {{name}}, with a description of {{description}}, and include {{sidebar_list}} in the sidebar?',\n",
    "        #'Post my question, \"{{question}}\", in a subreddit where I\\'m likely to get an answer',\n",
    "        #'Find a subreddit focused on topics related to {{topic}}, and post my question, \"{{question}}\" there',\n",
    "        'Edit my post on {{post}} by adding a line to the body that says \"{{content}}\"',\n",
    "        'Thumbs down the top {{k}} post ever in {{subreddit}}.',\n",
    "        #'Reply to {{position_description}} in this post with \"{{content_description}}\"',\n",
    "        #'Post in {{subreddit}} forum about what could open-source LLMs help the correpong field.',\n",
    "        #'Post in {{subreddit}} subreddit about what could diffusion model help the correpong field.',\n",
    "        #'Post in {{subreddit}} subreddit about what could midjourney help the correpong field.'\n",
    "    ]\n",
    "    random.seed(time.time())\n",
    "    # 随机选择 k 个\n",
    "    return random.sample(intensions, k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42145844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Among the top {{number}} post in \"{{subreddit}}\" forum, {{description}}',\n",
       " 'Change my reddit bio to \"{{content}}\"',\n",
       " 'Edit my post on {{post}} by adding a line to the body that says \"{{content}}\"',\n",
       " 'Thumbs down the top {{k}} post ever in {{subreddit}}.',\n",
       " 'Open the thread of a trending post on the forum \"{{subreddit}}\" and subscribe.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_select_webarena_intension(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4e198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_persona(personas):\n",
    "    random.seed(time.time())\n",
    "    return personas[random.randint(0, len(personas) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "883ca2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = []\n",
    "# with open(\"/home/zjusst/qms/persona-hub/data/elite_personas_10000.jsonl\", \"r\") as f:\n",
    "with open(\"/home/zjusst/qms/persona-hub/data/persona.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        persona = json.loads(line)\n",
    "        personas.append(persona['persona'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e80ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A classmate who is always excited to hear about the latest races and dreams of attending a race together'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona = random_persona(personas)\n",
    "persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc601ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://reddit.com/search?q=forum+exploration',\n",
       " \"Tab 0 (current): Search\\n\\n[5853] RootWebArea 'Search' focused: True\\n\\t[6041] HeaderAsNonLandmark ''\\n\\t\\t\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_url, a11y = random_select_url_and_a11y(prefix_to_record_dict)\n",
    "real_url, a11y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d10b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are an expert AI specializing in simulating realistic human-computer interaction. Your mission is to generate a single, high-quality user goal based on a given Persona and a Seed Page from a website. This goal will be used to guide an autonomous agent in exploring a website.\n",
    "\n",
    "Note: \n",
    "1. Your response MUST begin with the exact phrase `As a [Persona], my goal is to...`. The goal you generate should be a natural and logical objective for someone with that persona's background, needs, and motivations.\n",
    "2. Create a Challenging and Informative Goal. The goal should be non-trivial and likely require a sequence of logical steps (e.g., navigating, searching, comparing, finding specific information). Avoid simple, single-click tasks. The goal must be concrete and specific.\n",
    "3. Be Creative. Use the Persona and the Seed Page as inspiration to create a believable scenario. The seed page can be part of the goal.\n",
    "4. Go beyond just post or comment actions. You can infer these example short goal to **avoid** just post or comment actions: {example_short_goal}\n",
    "5. Don't generate multiple goals at a time. You should generate one or two goals that focus on one specific function of the website.\n",
    "\n",
    "Your output should be a single, coherent sentence that clearly states this challenging, persona-driven goal.'''\n",
    "\n",
    "user_prompt_template = '''\n",
    "URL: {url}\n",
    "A11y: {a11y}\n",
    "Persona: {persona}\n",
    "'''\n",
    "\n",
    "few_shot_examples = [\n",
    "    (\n",
    "        \"\"\"URL: http://reddit.com/f/relationship_advice\n",
    "A11y: Tab 0 (current): relationship_advice\n",
    "\n",
    "[3036] RootWebArea 'relationship_advice' focused: True\n",
    "[3049] main ''\n",
    "\t\t[3239] heading '/f/relationship_advice'\n",
    "\t\t[3053] button 'Sort by: Hot' focused: True hasPopup: menu expanded: True\n",
    "\t\t[4806] link '• Hot'\n",
    "\t\t[4803] link 'New'\n",
    "\t\t[4800] link 'Active'\n",
    "\t\t[4816] link 'Top'\n",
    "\t\t[4809] link 'Controversial'\n",
    "\t\t[4815] link 'Most commented'\n",
    "\t\t[3054] article ''\n",
    "\t\t\t[3057] HeaderAsNonLandmark ''\n",
    "\t\t\t\t[3298] heading 'Need advice on handling infidelity'\n",
    "\t\t\t\t\t[3702] link 'Need advice on handling infidelity'\n",
    "\t\t\t\t[3704] StaticText 'Submitted by '\n",
    "\t\t\t\t[3060] link 'MarvelsGrantMan136' expanded: False\n",
    "\t\t\t\t[3706] time 'October 9, 2025 at 3:48:16 AM EDT'\n",
    "\t\t\t\t\t[4179] StaticText '11 days ago'\n",
    "\t\t\t[4180] link '2 comments'\n",
    "\t\t\t[4182] link 'Edit'\n",
    "\t\t\t[4736] button 'Delete'\n",
    "\t\t\t[3302] button 'Retract upvote'\n",
    "\t\t\t[3305] button 'Downvote'\n",
    "\n",
    "Persona: A PhD candidate in remote sensing and machine learning, specifically focused on change detection of Arctic glaciers using satellite imagery and deep learning algorithms. The candidate has experience in developing and implementing data-driven methods for landscape change analysis and has completed a Master's degree in Geography and Environmental Sciences. The candidate is interested in using cutting-edge technology and machine learning techniques to understand and predict changes in Arctic glaciers, with the ultimate goal of informing and engaging communities about the impacts of climate change. The candidate is a strong researcher with a focus on developing innovative tools and user-friendly mapping solutions for the Arctic region.\"\"\",\n",
    "    #'As a PhD candidate in remote sensing and machine learning, my goal is to find a subreddit focused on topics related to geospatial data science or climate change, and post my question, \"What open-source LLMs are best suited for analyzing and summarizing satellite imagery time-series data for Arctic glacier change detection?\"'\n",
    "\t'As a PhD candidate in remote sensing and machine learning, my goal is to browse posts about remote sensing and machine learning and give likes to good ones.'\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "URL: http://reddit.com/f/worldnews\n",
    "A11y: Tab 0 (current): worldnews\n",
    "\n",
    "[2827] RootWebArea 'worldnews' focused: True\n",
    "[2845] main ''\n",
    "\t\t[3030] heading '/f/worldnews'\n",
    "\t\t[3540] link 'Submissions'\n",
    "\t\t[3541] link 'Comments'\n",
    "\t\t[2849] button 'Sort by: Hot' hasPopup: menu expanded: False\n",
    "\t\t[2850] article ''\n",
    "\t\t\t[2853] HeaderAsNonLandmark ''\n",
    "\t\t\t\t[3089] heading 'Ireland Aims To Legalize Cannabis For Personal Use'\n",
    "\t\t\t\t\t[3543] link 'Ireland Aims To Legalize Cannabis For Personal Use'\n",
    "\t\t\t\t[3091] link 'forbes.com'\n",
    "\t\t\t\t[3546] StaticText 'Submitted by '\n",
    "\t\t\t\t[2856] link 'seebz69' expanded: False\n",
    "\t\t\t\t[4046] StaticText 't3_z6vut3'\n",
    "\t\t\t\t[3550] time 'November 28, 2022 at 7:55:11 AM EST'\n",
    "\t\t\t\t\t[4050] StaticText '3 years ago'\n",
    "\t\t\t[4051] link '201 comments'\n",
    "\t\t\t[3095] button 'Upvote'\n",
    "\t\t\t[3553] StaticText '10614'\n",
    "\t\t\t[3098] button 'Downvote'\n",
    "\n",
    "Persona: A geophysicist who specializes in studying the properties and behavior of the Earth's core, particularly in relation to its composition and structure. He or she is interested in understanding how the core is formed, how it changes over time, and how it interacts with the rest of the planet. This person may have expertise in using advanced technology, such as the University of Chicago's laser-heated diamond anvil cell, to study the inner core. They may also be interested in exploring the potential for the inner core to be a mixture of different crystal phases, such as hexagonal close-packed and body-centered cubic iron, and how this could affect the Earth's magnetic field and other geological processes.\"\"\",\n",
    "\t\"As a geophysicist who specializes in studying the properties and behavior of the Earth's core, my goal is edit my last post and add content about the inner core.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d89090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(user_prompt_template.format(url=real_url, a11y=tmp_a11y, persona=persona))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "056cf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# import os\n",
    "\n",
    "# os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "# os.environ['LANGSMITH_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "# os.environ['LANGSMITH_API_KEY'] = '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'\n",
    "# os.environ['LANGSMITH_PROJECT'] = 'pr-wooden-hedgehog-65'\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-khwk6tpwWCA7ANFoljLONZ4Xln766pTzuEkDkEXYvxdzNcXQ'\n",
    "# os.environ['OPENAI_API_BASE'] = 'https://api2.aigcbest.top/v1'\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o\",\n",
    "#     api_key=\"sk-khwk6tpwWCA7ANFoljLONZ4Xln766pTzuEkDkEXYvxdzNcXQ\",\n",
    "#     base_url=\"https://api2.aigcbest.top/v1\"\n",
    "# )\n",
    "# print(llm.invoke(\"hello\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a651ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "os.environ['LANGSMITH_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGSMITH_API_KEY'] = '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'\n",
    "os.environ['LANGSMITH_PROJECT'] = 'pr-wooden-hedgehog-65'\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-g4MycviIFf8Lad0v5zVKPljDpueIDBLuqIC1nsDAiRnLZVKg'\n",
    "os.environ['OPENAI_API_BASE'] = 'https://api2.aigcbest.top/v1'\n",
    "\n",
    "from typing import Any, List, Dict\n",
    "\n",
    "# LangChain 和 LangSmith 的相关导入\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ChatMessage\n",
    "\n",
    "def generate_from_openai_chat_completion_new(\n",
    "    messages: List[Dict[str, str]],\n",
    "    model: str,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    top_p: float,\n",
    "    context_length: int, # 这个参数在ChatOpenAI中不直接使用，但为了保持签名一致而保留\n",
    "    stop_token: str | None = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    使用 LangChain 的 ChatOpenAI 生成聊天回复，并支持 LangSmith 追踪。\n",
    "    函数签名与旧版完全兼容。\n",
    "    \"\"\"\n",
    "    if \"OPENAI_API_KEY\" not in os.environ and \"api_key\" not in locals():\n",
    "        raise ValueError(\"OPENAI_API_KEY environment variable must be set.\")\n",
    "\n",
    "    # 1. 初始化 LangChain 的 ChatOpenAI 客户端\n",
    "    # 将旧函数的参数映射到 ChatOpenAI 的构造函数中\n",
    "    llm = ChatOpenAI(\n",
    "        # 从环境变量获取 key 和 base_url，提供默认值\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        stop=[stop_token] if stop_token else None,\n",
    "        model_kwargs={}, # 如果没有其他高级参数，可以为空字典或直接省略\n",
    "        # 内置重试机制，替代旧的装饰器\n",
    "        max_retries=3,\n",
    "    )\n",
    "\n",
    "    # 2. 将输入的字典列表转换为 LangChain 的消息对象\n",
    "    # 这是一个必要的适配步骤\n",
    "    langchain_messages = []\n",
    "    for msg in messages:\n",
    "        role = msg.get(\"role\")\n",
    "        content = msg.get(\"content\", \"\")\n",
    "        # 从字典中获取 name，如果不存在则为 None\n",
    "        name = msg.get(\"name\")\n",
    "\n",
    "        if role == \"user\":\n",
    "            langchain_messages.append(HumanMessage(content=content, name=name))\n",
    "        elif role == \"assistant\":\n",
    "            langchain_messages.append(AIMessage(content=content, name=name))\n",
    "        elif role == \"system\":\n",
    "            # 这会正确处理您提供的 few-shot 示例\n",
    "            langchain_messages.append(SystemMessage(content=content, name=name))\n",
    "        else:\n",
    "            # 为其他可能的角色（如 'tool'）提供一个通用处理\n",
    "            langchain_messages.append(ChatMessage(role=role, content=content))\n",
    "\n",
    "    # 3. 调用 LLM 并获取结果\n",
    "    response = llm.invoke(langchain_messages)\n",
    "\n",
    "    # 4. 提取并返回内容，保持与旧函数相同的字符串输出\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a4861a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_messages_with_name = [\n",
    "#     {\n",
    "#         'role': 'user',\n",
    "#         \"content\": \"hello\"\n",
    "#     }\n",
    "# ]\n",
    "# result = generate_from_openai_chat_completion_new(\n",
    "#     messages=example_messages_with_name,\n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=2000,\n",
    "#     top_p=1.0,\n",
    "#     context_length=4096,\n",
    "#     stop_token=None\n",
    "# )\n",
    "# print(\"LLM Response:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "799eb048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: As a dedicated videographer capturing the halftime performance from different angles, my goal is to find recent comments discussing video techniques or equipment used for capturing live performances and analyze them to gather insights for improving my own videography skills.\n",
      "LLM Response: As a debate tournament organizer who appreciates the input and insights from the input persona, my goal is to reach out to MarvelsGrantMan136 via private message to discuss the possibility of hosting a debate on the impact of climate change on Arctic glaciers, incorporating remote sensing and machine learning as part of the discussion framework.\n",
      "LLM Response: As a retired Marine Corps Air Traffic Controller who served in MATCS-38 during the Gulf War, my goal is to create a forum dedicated to military aviation history and discussions to connect with other veterans and enthusiasts, sharing experiences and insights from my service.\n",
      "LLM Response: As an online sports commentator who follows cross country events and loves to support underdogs, my goal is to navigate through the search results to find and engage with a post that creatively uses sports as a metaphor in writing prompts, adding my insights on how such metaphors can inspire resilience and innovation in storytelling.\n",
      "LLM Response: As a young child interested in learning about how different foods affect their energy levels, my goal is to create a new forum focusing on nutritional topics, with the name \"Energy Food Explorers,\" a descriptive title such as \"Discover How Foods Impact Your Energy,\" and a sidebar featuring weekly challenges to explore and discuss the effects of various foods on energy levels.\n",
      "LLM Response: As a retired music teacher who remembers the musician practicing late nights in their garage, my goal is to explore MarvelsGrantMan136's submissions to find content related to music or musicians, and analyze the posts to understand how modern platforms discuss music-related topics.\n",
      "LLM Response: As a foreign ambassador promoting international collaboration in scientific research, my goal is to find and review discussions in the \"science\" forum that focus on international research partnerships and contribute insights or experiences that could encourage further collaboration.\n",
      "LLM Response: As a Toni Morrison fan who loves literature, language, and contemporary American history, my goal is to create a new forum dedicated to discussing the themes and historical contexts of Toni Morrison's novels and invite fellow enthusiasts to contribute.\n",
      "LLM Response: As a monarch who values loyalty and discretion, my goal is to explore the 'Top 25 TV Shows of 2022' list to identify a series that features themes of loyalty and discretion, and then write a comment under that show discussing how these themes are portrayed and their relevance to leadership.\n",
      "LLM Response: As a worker who was laid off during Medly's downfall, my goal is to navigate the block list page to find and block any users that are currently causing stress or negativity in my online interactions, ensuring a more positive online experience.\n",
      "LLM Response: As a software engineer who designs programs for real-time data collection during races, my goal is to explore posts about the new technology, focusing on articles related to world events and technological advancements, and analyze how I could possibly integrate these technologies into my current work for more efficient data handling.\n",
      "LLM Response: As a retired veteran who served as Samuel's commanding officer, my goal is to navigate to the most recent post in the relationship advice forum and offer guidance by commenting with advice based on my own leadership and life experiences.\n",
      "LLM Response: As a professor of industrial engineering conducting research on advanced simulation methods in materials manufacturing, my goal is to navigate to the forums and identify active discussions related to simulation techniques in materials manufacturing, and then contribute by sharing insights from my latest research findings.\n",
      "LLM Response: As a local resident of Qinghai Province who relies on traditional farming, my goal is to explore recent world news articles related to agriculture policies or climate change, specifically looking for discussions on how these might impact farming practices in rural regions like Qinghai, and then share this information with my local community forum.\n",
      "LLM Response: As a film critic who specializes in 1960s cinema, my goal is to explore the search results for 'technology forums' to find and analyze discussions about the technological advancements in movie-making during the 1960s, and to contribute insights on how these innovations influenced the film industry of that era.\n",
      "LLM Response: As an enthusiastic college football fan, my goal is to explore and comment on a post in the movies forum that discusses a movie about college sports, focusing on how the film captures the spirit and sportsmanship of the game.\n",
      "LLM Response: As a retired propaganda filmmaker, my goal is to revisit my list of submissions and craft a detailed post reflecting on the techniques and challenges of creating wartime propaganda, drawing from my personal experiences, to foster a discussion on its impact on public perception during historical conflicts.\n",
      "LLM Response: As a grandparent who enjoys spoiling the grandchildren with travel-related gifts and souvenirs, my goal is to find and explore forums that discuss travel destinations and gift ideas for family vacations, and save the most interesting ones for future reference.\n",
      "LLM Response: As a physical therapist who frequently debates the merits of medical dramas versus real-life procedures, my goal is to search for discussions comparing medical dramas to actual medical practices and contribute by posting a detailed analysis of a specific episode's portrayal of physical therapy in relation to real-world scenarios.\n",
      "LLM Response: As a philosopher exploring the nature of power and its impact on society, my goal is to search for forums discussing philosophical theories and engage in thought-provoking discussions on how power dynamics shape societal structures, aiming to contribute a well-considered perspective and potentially write a comprehensive post about my insights.\n",
      "LLM Response: As a retired executive living in a luxurious penthouse, my goal is to update my user settings by changing the language to French and enabling notifications for replies to my posts, ensuring I stay informed about interactions and discussions related to the latest trends.\n",
      "LLM Response: As a behavioral economist, my goal is to compare and analyze user comments on different events happening in Boston this weekend to see if there are any patterns in emotional and irrational responses to cultural and entertainment choices.\n",
      "LLM Response: As an innovative software developer focused on rehabilitation apps, my goal is to subscribe to the 'worldnews' forum to stay informed about global events that could impact healthcare technology and then explore the latest submissions to identify articles related to advancements in medical technology and software development.\n",
      "LLM Response: As a social worker who witnesses firsthand the negative effects of tech startups on marginalized communities, my goal is to find and engage in discussions about tech startups and their impact on society, particularly by searching for recent comments related to this topic and contributing my insights and experiences.\n",
      "LLM Response: As a screenplay writer tackling writer's block and often finding inspiration from the most mundane experiences, my goal is to create a new forum dedicated to screenplay writing, with a description that encourages sharing everyday stories that spark creativity, and to include a sidebar list of tips for overcoming writer's block.\n",
      "LLM Response: As a farmer deeply impacted by a recent flood, my goal is to find and participate in a discussion on the relationship_advice forum about how to handle and recover from natural disasters, and share my own experiences and seek guidance on restoring my land.\n",
      "LLM Response: As a film music composer who values artistic dedication and expressive lyrics, my goal is to explore the \"Wiki\" section to find discussions or articles about the impact of film music on storytelling and then share my insights on how music composition can enhance cinematic narratives.\n",
      "LLM Response: As a gal who is heavily sceptical of crime investigations, my goal is to create a thoughtful submission in a forum dedicated to discussing controversial legal cases, where I question the use of forensic evidence in a high-profile trial and encourage users to debate its validity while presenting my arguments in the body of the post.\n",
      "LLM Response: As a highly sought-after and award-winning actor, my goal is to navigate to the 'User settings' page and update my contact information to ensure my talent agent can reach me with new offers and opportunities seamlessly.\n",
      "LLM Response: As an entrepreneur planning to build a historically-themed hotel and restaurant chain, my goal is to create a submission on Reddit explaining my business concept and seeking advice on integrating local historical elements into the design to attract culturally curious travelers, while navigating through various forums to identify the most active and relevant community for potential collaboration and feedback.\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "\n",
    "# 使用您提供的包含 'name' 字段的 messages 列表\n",
    "\n",
    "    real_url, a11y = random_select_url_and_a11y(prefix_to_record_dict)\n",
    "    persona = random_persona(personas)\n",
    "    short_goal = random_select_webarena_intension(5)\n",
    "    example_messages_with_name = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt.format(example_short_goal=short_goal)\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_user',\n",
    "            'content': few_shot_examples[0][0]\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_assistant',\n",
    "            'content': few_shot_examples[0][1]\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_user',\n",
    "            'content': few_shot_examples[1][0]\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_assistant',\n",
    "            'content': few_shot_examples[1][1]\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'name': 'user',\n",
    "            'content': user_prompt_template.format(url=real_url, a11y=a11y, persona=persona)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 调用修正后的新函数\n",
    "    try:\n",
    "        result = generate_from_openai_chat_completion_new(\n",
    "            messages=example_messages_with_name,\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000,\n",
    "            top_p=1.0,\n",
    "            context_length=4096,\n",
    "            stop_token=None\n",
    "        )\n",
    "        print(\"LLM Response:\", result)\n",
    "        with open(f\"/home/zjusst/qms/webarena/result_stage_2_intended_explore/generated_intensions_v2.txt\", \"a\") as f:\n",
    "            f.write(result + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1856bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "start_index = 850\n",
    "config_json_save_dir_name = \"/home/zjusst/qms/webarena/config_files\"\n",
    "\n",
    "config_template = {\n",
    "  \"sites\": [\n",
    "    \"reddit\"\n",
    "  ],\n",
    "  \"task_id\": 812,\n",
    "  \"require_login\": True,\n",
    "  \"storage_state\": \"./.auth/reddit_state.json\",\n",
    "  \"start_url\": \"http://10.130.138.30:9999\",\n",
    "  \"geolocation\": None,\n",
    "  \"intent_template\": \"N/A\",\n",
    "  \"instantiation_dict\": {\n",
    "    \"forum\": \"N/A\"\n",
    "  },\n",
    "  \"intent\": \"Default\",\n",
    "  \"require_reset\": False,\n",
    "  \"eval\": {\n",
    "    \"eval_types\": [\n",
    "      \"string_match\"\n",
    "    ],\n",
    "    \"reference_answers\": {\n",
    "      \"must_include\": [\n",
    "        \"0\"\n",
    "      ]\n",
    "    },\n",
    "    \"reference_url\": \"\",\n",
    "    \"program_html\": [],\n",
    "    \"string_note\": \"\",\n",
    "    \"reference_answer_raw_annotation\": \"0\"\n",
    "  },\n",
    "  \"intent_template_id\": \"N/A\"\n",
    "}\n",
    "\n",
    "generate_instructions = []\n",
    "with open(f\"/home/zjusst/qms/webarena/result_stage_2_intended_explore/generated_intensions_v2.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        generate_instructions.append(line.strip())\n",
    " \n",
    "for i in range(len(generate_instructions)):\n",
    "    config_json = config_template\n",
    "    config_json[\"task_id\"] = start_index + i\n",
    "    config_json[\"intent\"] = generate_instructions[i]\n",
    "    with open(f\"{config_json_save_dir_name}/{start_index + i}.json\", \"w\") as f:\n",
    "        json.dump(config_json, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webarena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
